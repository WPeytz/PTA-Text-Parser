## ğŸ“˜ PTA Text Parser

This project extracts, processes, and analyzes legal text from a Preferential Trade Agreement (PTA) â€” specifically the EUâ€“South Korea Free Trade Agreement. The focus is on the Rules of Origin section, which defines the criteria for goods to qualify as originating under the agreement.

---

## ğŸš€ What It Does

- Scrapes HTML content from the EUâ€™s legal document portal using `requests` and `BeautifulSoup`
- Parses individual paragraphs and assigns them to legal articles
- Cleans and filters to ensure only actual articles (e.g., â€œArticle 3â€) are retained
- Counts words per article to identify verbosity champions
- Searches for keywords related to trade policy using regex (e.g., â€œoriginatingâ€, â€œcumulationâ€)
- Visualizes:
  - Word counts per article
  - Keyword frequency

---

## ğŸ“‚ Files

- `PTA_Text_Parser.py` â€“ Main script (scraping, parsing, analyzing, plotting)
- `pta_rules_of_origin.csv` â€“ Cleaned dataset of article-paragraph mappings
- `wordcount_per_article.png` â€“ Bar chart of top 15 longest articles
- `keyword_frequencies.png` â€“ Bar chart of keyword frequency in text
- `pta_explorer.py` â€“ Streamlit app for interactive exploration

---

## ğŸ” Example Output

### Top 5 Longest Articles:

Article 3    1223 words
Article 6     999 words
Article 5     901 words
Article 1     899 words
Article 2     814 words

### Keyword Occurrences (with regex):
originating: 17
cumulation: 1
tolerance: 0
HS: 0

---

## âš™ï¸ How to Run

1. Clone the repo:
```bash
git clone https://github.com/yourname/PTA-Text-Parser.git
cd PTA-Text-Parser
```
2.	Install requirements (optional: use a virtual environment):

```bash
pip install -r requirements.txt
```
3.	Run the parser:
```bash
python PTA_Text_Parser.py
```
ğŸ§  Future Improvements
	â€¢	Tag paragraphs by type: definition, procedure, exception
	â€¢	Add section-level parsing beyond â€œArticle Xâ€
	â€¢	Expand keyword dictionary using NLP techniques
	â€¢	Integrate Streamlit UI for interactive exploration

ğŸ’¡ Why This Project?

Because someone had to read the legalese so you didnâ€™t have to â€” and I wanted to prove I can extract meaningful structure and analysis from complex text data using Python and beautiful soup.